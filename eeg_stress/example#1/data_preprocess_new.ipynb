{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import math\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from os.path import exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "68 17\n"
     ]
    }
   ],
   "source": [
    "participants = 89\n",
    "excluded_numbers = [8, 35, 39, 81]\n",
    "label_file_path='./details/labels.csv'\n",
    "subjects = [idx for idx in range(1, participants+1) if idx not in excluded_numbers]\n",
    "random.shuffle(subjects)\n",
    "print(len(subjects))\n",
    "subjects_train = subjects[:int(len(subjects)*0.8)]\n",
    "subjects_test = subjects[int(len(subjects)*0.8):]\n",
    "print(len(subjects_train), len(subjects_test))\n",
    "\n",
    "window_time = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subject):\n",
    "    if exists('./../../eeg_data/{}.mat'.format(subject)):\n",
    "        file = './../../eeg_data/{}.mat'.format(subject)\n",
    "        mat_data = loadmat(file)\n",
    "        eeg_data = (mat_data['EEG']['data'][0, 0])*1e-6\n",
    "        channel_names = [ch[0] for ch in mat_data['EEG']['chanlocs'][0, 0]['labels'][0]]\n",
    "        sampling_freq = mat_data['EEG']['srate'][0, 0][0, 0]\n",
    "        return eeg_data, channel_names, sampling_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(select_data, label):\n",
    "\n",
    "    shape = np.shape(select_data)\n",
    "    # 计算要拆分的段数\n",
    "    num_segments = shape[1] // (window_time*250)\n",
    "    select_data = select_data[:, 0:num_segments*window_time*250]\n",
    "    # 使用 `np.split()` 函数进行拆分\n",
    "    segments = np.split(select_data, num_segments, axis=1)\n",
    "\n",
    "    features = []\n",
    "    for seg in segments:\n",
    "        seg_fft = []\n",
    "        for i in range(seg.shape[0]):\n",
    "            # [:64]表示只取前64个频率分量的结果\n",
    "            fft = np.abs(np.fft.fft(seg[i, :]))[0:64]\n",
    "            fft = fft / np.sum(fft)\n",
    "            seg_fft.append(fft)\n",
    "            # print(\"fft.type: \", type(fft))\n",
    "        feat = np.concatenate(seg_fft, axis = 0)\n",
    "        # print(len(feat))   # 128\n",
    "        features.append((feat, label))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in subjects_train:\n",
    "    df = pd.read_csv(label_file_path)\n",
    "\n",
    "    # 读取这个csv文件的Tension (1, 8, 15, 21, 28, and 35)列中ID为i的行的值，如果这个值小于等于15，那么label为0，否则为1\n",
    "    tension_value = df.loc[df['ID'] == i, 'Tension (1, 8, 15, 21, 28, and 35)'].values[0]\n",
    "    if tension_value<=15:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "\n",
    "    eeg_data, channel_names, sampling_freq = load_data(i)\n",
    "    # print(eeg_data.shape, channel_names, sampling_freq)\n",
    "\n",
    "    eeg_data_fp1 = eeg_data[channel_names.index('FP1'), : ]\n",
    "    eeg_data_fp2 = eeg_data[channel_names.index('FP2'), : ]\n",
    "    # print(eeg_data_fp1.shape, eeg_data_fp2.shape)\n",
    "\n",
    "    # 把eeg_data_fp1和eeg_data_fp2的数据拼接在一起，成为一个二维数组\n",
    "    eeg_data_fp1 = eeg_data_fp1.reshape(1, -1)\n",
    "    \n",
    "    eeg_data_fp2 = eeg_data_fp2.reshape(1, -1)\n",
    "    eeg_data = np.concatenate((eeg_data_fp1, eeg_data_fp2), axis=0)\n",
    "\n",
    "    features = get_features(eeg_data, label)\n",
    "\n",
    "    train_data += features\n",
    "\n",
    "for i in subjects_test:\n",
    "    df = pd.read_csv(label_file_path)\n",
    "\n",
    "    # 读取这个csv文件的Tension (1, 8, 15, 21, 28, and 35)列中ID为i的行的值，如果这个值小于等于15，那么label为0，否则为1\n",
    "    tension_value = df.loc[df['ID'] == i, 'Tension (1, 8, 15, 21, 28, and 35)'].values[0]\n",
    "    if tension_value<=15:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "\n",
    "    eeg_data, channel_names, sampling_freq = load_data(i)\n",
    "    # print(eeg_data.shape, channel_names, sampling_freq)\n",
    "\n",
    "    eeg_data_fp1 = eeg_data[channel_names.index('FP1'), : ]\n",
    "    eeg_data_fp2 = eeg_data[channel_names.index('FP2'), : ]\n",
    "    # print(eeg_data_fp1.shape, eeg_data_fp2.shape)\n",
    "\n",
    "    # 把eeg_data_fp1和eeg_data_fp2的数据拼接在一起，成为一个二维数组\n",
    "    eeg_data_fp1 = eeg_data_fp1.reshape(1, -1)\n",
    "\n",
    "    eeg_data_fp2 = eeg_data_fp2.reshape(1, -1)\n",
    "    eeg_data = np.concatenate((eeg_data_fp1, eeg_data_fp2), axis=0)\n",
    "\n",
    "    features = get_features(eeg_data, label)\n",
    "\n",
    "    test_data += features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到文件: samples\\window_2s_test.pkl\n"
     ]
    }
   ],
   "source": [
    "# 指定要保存的文件名和文件夹路径,如果没有的话生成这个文件夹\n",
    "folder_name = 'samples'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "filename = os.path.join(folder_name, 'window_{}s_train.pkl'.format(window_time))\n",
    "\n",
    "# 使用 pickle.dump() 将数据保存到文件中\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(train_data, file)\n",
    "\n",
    "filename = os.path.join(folder_name, 'window_{}s_test.pkl'.format(window_time))\n",
    "\n",
    "# 使用 pickle.dump() 将数据保存到文件中\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(test_data, file)\n",
    "\n",
    "print(\"数据已保存到文件:\", filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
